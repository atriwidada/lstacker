{
  "name": "Lstacker",
  "tagline": "A virtual network infrastructure builder.",
  "body": "# LStacker\r\n\r\nThe LStacker project is a virtual infrastructure builder. It builds a virtual container based network on top of the infrastructure supplied to it. Using this approach enables an organisation to quickly build its infrastructure on minimul hardware, in and out of the cloud. Thus maximizing investement.\r\n\r\n## Update\r\nThe container creation and destroy commands have now been tested and work correctly, I am now testing the network an profile creation processes. When this process is complete iwill be possible to stack an entire network matching your requirements.\r\n\r\n## Approach\r\nLStacker is designed to use a simple build and deploy process and provides the following:\r\n\r\n* A simple Yaml configuration file is used to define the network and server infrastructure.\r\n* Infrasture is built on top of simple vanilla VM's or Cloud instances. And can easily be rebuilt at any stage. [Ubuntu](http://www.ubuntu.com/) 16.04 is a requirement at present.\r\n* [LXD](https://linuxcontainers.org/lxd/) is used to build out the server container infrastucture.\r\n* [Docker](https://www.docker.com/) is fully supported and docker swarm can be used to bring up complex applications.\r\n* A virtual network using a GRE/VxLAN bridge enables all containers to communicate with each other across the infrastructure. Be they on one or multiple servers. Openvswitch is used to manage this network.\r\n* The virtual network is normally divided into the following components:\r\n    * Management network: This network is setup to enable the management processes to communicate with the containers. This will be used by monitoring processes such as check_mk, or by the dns server.\r\n    * Test network: This network is used for test purposes. If you want to play around with technology use this network.\r\n    * Development network: This is used for development purposes.\r\n    * QA network: A network for QA purposes\r\n    * Production network: A network for production purposes.\r\n* A jump-box is built as a means to access the virtual network. Use [sshuttle](http://sshuttle.readthedocs.io/) to setup a VPN like connection into the jump-box and then access all the virtual infrastructure as if you were on the network. Multiple can be built if horizontal loading within the network is a requirement.\r\n* At present production instances can be exposed by port mapping onto a reverse proxy like haproxy. This is a recommended service for the jump box.\r\n\r\n## Instastructure\r\nI recommend running on a minum of 4 either virtual machines or cloud instances. These you can allocate as you see fit in your Lstacker build file. If you are worried about the costs then use micro instances on EC2 will work, but more may have to be allocated. This will not cause a problem with the build process. If cost is not a factor than I recommend a medium instance or higher.\r\n\r\n1. Install vanilla version of [Ubuntu](http://www.ubuntu.com/download/server) 16.04 onto the target virtual machines or cloud instances.\r\n2. Ear mark a virtual machine or instance as the master server and setup ssh access from it to the other instances.\r\n3. Clone this project and add it to the PATH environment variable on the master server.\r\n\r\n## LXD Setup\r\nLXD/LXC has to be configured appropriatly.\r\n\r\n1. Init LXD using the `lxd init` command. This has to be peformed on all boxes. Select the configuration that makes the most sense for your environment. I recommend running on a ZFS pool, if this is not available than a standard dir backend will work fine.\r\n2. The management port has to be exposed and the trust password set on all lxd instances.\r\n\r\n    ```\r\n    sudo lxc config set core.https_address [::]\r\n    sudo lxc config set core.trust_password some-password\r\n    ```\r\n\r\n3. All LXD servers have to know about each other. This requires they are registered as remotes with each other.\r\n   `sudo lxc remote add lxd1 <ip address or DNS of remote service>`\r\n\r\n\r\n## Openvswitch\r\nOpenvswitch has to be installed on all hosts. This can be done through apt as follows:\r\n\r\n```sudo apt install openvswitch-switch```\r\n\r\n## Build Process\r\n\r\n1. Setup a lstacker context directory.\r\n2. Write a `lstacker.yaml` file defining the network and infrastructure. There are example provided with this project.\r\n3. Build the infrastructure\r\n   `lstacker stack`\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}